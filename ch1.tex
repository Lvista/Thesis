% !TEX root = ch1.tex
%% ---DO NOT MODIFY BEGIN---
\ifx\allfiles\undefined
\input{.//config}
\begin{document}
% \makecover
\else
\fi
%% ---DO NOT MODIFY END---
%-------------------第1章------------------------
\section{序论}

\subsection{研究背景与意义}

近年来，无人机正在快速发展。自无人机从军事领域进入民用市场以来，无人机与各种活动相结合，大大扩展了人们的活动范围。根据数据库STATISTA\footnote{\texttt{https://www.statista.com/}}的统计，无人机市场的收益显著增长。如图\ref{fig:Drone revenue}所示，自2020年以来，全球无人机市场的销售额从29亿美元稳步增长，到2023年达到了40亿美元。此外，预计到2029年将达到49亿美元。

无人机凭借其独特的优势，在各个领域得到广泛应用，展现出社会、经济和科学价值。无人机从监控侦察、航拍到电力线检查等实际应用场景，涵盖范围广泛，为不同领域提供了高效且创新的解决方案。
\begin{figure}[htbp]
    \centering
    \includegraphics[width=1\linewidth]{fig/1.1-data.pdf}
    \caption{全球无人机市场收益}
    \label{fig:Drone revenue}
\end{figure}

虽然无人机在自动化方面的能力不断提高，但在特定的飞行阶段（例如着陆阶段）或面临无法预料的突发情况时，仍需要切换到手动操作模式。这种切换不仅提高了操作的灵活性，还能确保飞行安全。此外，在空中摄影和救援活动等需要高度实时判断的任务中，实时的人为监控和干预尤为重要，手动操作是不可避免的。

然而，传统的遥控器需要占用双手，依赖手指进行操作。现代无人机需要同时控制无人机的运动和周边模块，传统的遥控器界面限制了操作功能的扩展。因此，近年来人-无人机交互（HDI，Human Drone Interaction）的研究和开发迅速发展，研究者们正在探索提供移动性、多功能性和直观体验的新型交互方式。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=.8\linewidth]{fig/1.2-RC.pdf}
    \caption{市售无人机遥控器(https://www.shutterstock.com)}
    \label{fig:2.1-Controller}
\end{figure}

\subsection{无人机交互技术现状}

随着机器应用领域从传统的军事和工业领域扩展到物流、农业、娱乐、医疗等多个行业，人机交互技术的重要性日益凸显。HDI是指人与无人机之间使用特定的通信语言，通过一定的交互方式，为完成既定任务而进行的信息交换过程。由于四旋翼无人机在三维空间中自由飞行的独特特性和前所未有的机械构型，使得HDI成为一个独立且重要的研究课题\cites{tezza2019state}。研究HDI具有重要的战略价值和经济价值\cites{kyrkou2019drones,CUI2022135}。

根据交互方式的不同特征，无人机交互可分为三种主要类型\cites{tezza2019state}：

\begin{itemize}
    \item 模仿型交互：无人机直接模仿用户动作，例如将操作者的手部动作直接转换为机体姿态变化
    \item 仪表型交互：使用物理或虚拟设备作为中间介质，例如传统的摇杆控制方式
    \item 智能型交互：操作员通过高级指令与无人机进行交互，如发出"跟随我"等语音命令。
\end{itemize}

人与无人机之间的信息交换是双向的过程，其中人对无人机发送控制信息的行为可以用遥控来描述。在遥控系统中，位置控制是核心组成部分。根据控制方式的不同，位置控制可分为四种主要范式\cites{funk2018human}：直接位置控制、绝对位置控制、相对位置控制和任务导向控制。

目前市售无人机大多采用直接位置控制方式，用户通过遥控器直接操作无人机位置，如图\ref{fig:2.1-Controller}所示的摇杆式遥控器。然而，这种传统控制方式存在设备体积大、界面不够直观、需要双手操作等挑战。因此，研究者们正在探索基于新模式和新界面的替代交互方法。

基于最近的研究，控制模式可分为遥控器、手势、语音、眼动、脑波、多模态几个类别。表\ref{tab:summery}总结了无人机交互模式和过去5年的相关研究。

\begin{table}[htbp]
    \centering
    \caption{最新无人机交互研究}
    \begin{tabular}{|p{2cm}|p{8cm}|p{2cm}|}
        \hline
        交互类型   & 描述  & 相关研究  \\ \hline
        遥控器   & 将操作者的手部动作转换为摇杆和按钮等操作，映射为无人机控制指令的方法。例如游戏手柄和目前市售的许多无人机遥控器。 & \citeb{buttner2020one,kim2022intuitive}   \\ \hline
        手势或身体姿态 & 使用手部或身体姿态控制无人机的方法。分为静态手势控制和动态手势控制，将特定时点的身体或手部姿态，或动作轨迹映射为无人机控制指令。& \citeb{mughees2020gesture,nguyen2024pose,bello2023captainglove,budiyanto2021navigation,muezzinouglu2021intelligent,kim2020comparative,patrona2021overview,yau2020subtle,lee2023wearable,cherpillod2019embodied,rognon2018flyjacket,张伟锋2017,蔡成林0基于视觉,赫闻阳2020基于视觉,何磊2022基于深度学习,黑振全2022基于手势,于昌立2022基于数据手套,陶烨豪2024基于数据手套} \\ \hline
        语音 & 直接利用语音指令控制无人机的方法。可应用于地面控制站座椅界面、内部设备控制，甚至智能问答等，简化控制过程。 & \citeb{pirlet2022master,safie2024unmanned,夏渊湛2022基于STM32的语音}\\ \hline
        眼动追踪  &  将眼动数据转换为无人机控制指令的方法。使用眼动追踪器等设备获取操作者的视线坐标位置，控制无人机方向。 & \citeb{di2022natural}\\ \hline
        脑波（BCI）及肌电图 & 通过运动想象在大脑皮层运动感觉区域引起电位变化，利用该脑波信号控制无人机。还包括利用肌肉收缩时产生的微弱电流的方法。& \citeb{jeong2020towards,kim2021p300,zheng2022surface} \\ \hline
        多模态 & 结合多种自然交互技术，以多模式控制无人机，提高控制的稳定性和精度。例如，面部识别+语音识别、眼动控制+手势识别+语音识别的融合。 & \citeb{yoo2022motion,abioye2023multimodal,menshchikov2019data} \\ \hline
    \end{tabular}
    \label{tab:summery}
\end{table}

每种交互模式各有特点。Di等人\cites{di2022natural}比较了遥控器、眼动、手势三种方式，指出眼动控制能够实现精确控制，但容易受到头部和眼部运动联动的影响。语音控制界面的主要限制在于不同人对词汇含义的理解差异和指令的非连续性\cites{tezza2019state}。因此，与位置控制相比，语音控制界面在社交性方面具有更大的可能性，最近的研究主要集中在语音识别模型的优化上\cites{pirlet2022master,safie2024unmanned}。目前，使用脑波（EEG）的无人机界面主要处理离散指令\cites{jeong2020towards,kim2021p300}，但被指出由于技术等原因，目前脑波并不是自然的人机交互方式\cites{zheng2022surface}。相比之下，手势被认为是更自然且适合位置控制的交互方法。

\subsection{基于手势的交互控制}

手势交互界面的研究范围广泛，被认为是最直观且最有潜力的交互模式。在相关研究领域，手势的定义并不局限于手部的动作和姿态，也包括身体甚至面部的动作\cites{wu2024gesture}。手势识别可以取代鼠标\cites{prasanth2023gesture}和键盘等传统输入设备，提供更灵活、更直观的交互体验，以便人们可以更自由地与计算机互动。例如，通过手势，您可以控制计算机的操作、浏览网页、播放音乐\cites{clement2021musical}等等。此外，手势操作在虚拟现实、健康管理、智能家居等领域也展现出良好的应用前景\cites{wu2024gesture}。

根据Tezza等人\cites{tezza2019state}的研究，当要求用户在无指导情况下与无人机进行交互时，手势交互是多数用户的首选方式。研究进一步指出，通过使用手势代替传统摇杆与无人机进行协作，可以实现更加自然的操作体验，有助于提升用户的整体满意度和社会幸福感。

目前研究最为活跃的是基于图像识别的手势交互界面\cites{mughees2020gesture,蔡成林0基于视觉,赫闻阳2020基于视觉,黑振全2022基于手势}。然而，基于图像识别的方法要求用户必须保持在图像传感器的检测范围内，并且严重依赖于环境条件和光照状况。此外，图像识别的精度和延迟问题也构成了技术挑战，且手势含义的个体差异性也影响了系统的通用性。

因此，除了持续优化图像识别技术外，研究者们也在积极关注使用非视觉传感器的手势识别方法，例如IMU惯性测量单元\cites{yau2020subtle,lee2023wearable,yoo2022motion}、数据手套\cites{bello2023captainglove,muezzinouglu2021intelligent}、肌电信号\cites{zheng2022surface}、触摸板\cites{yau2020subtle}等。这些研究有效推动了自然交互界面的发展，其中许多技术方案都依赖于可穿戴设备的支持。

\subsection{可穿戴设备技术发展}

可穿戴设备最初仅用于实现简单功能，如传统手表主要用于时间显示。随着电子技术的快速发展，可穿戴设备获得了更多应用可能性。移动设备的集成度和运算能力快速提升，设备互联和无线通信技术的持续迭代，使移动设备的智能化程度进一步提高。特别是随着智能手机性能的显著提升和市场普及率的饱和，以智能手机为核心的外围移动设备成为新的技术发展趋势。

用户对可穿戴移动设备的兴趣日益增长，这些设备能够通过智能手机无法实现的方式改善生活质量。这些设备包括智能手表、智能腕带、智能眼镜、智能珠宝、电子纺织品、皮肤贴片等，统称为可穿戴设备\cites{seneviratne2017survey}。

可穿戴设备不仅具备良好的便携性，还与人类感官具有天然的亲和性，通过与人体在感觉、认知、情感等多个层面的接触，能够产生更优质的交互体验。特别是对于第一人称视角（First-Person View, FPV）的应用场景，可穿戴设备能够提供更加出色的沉浸式体验。此外，可穿戴设备具有持续开启的特性，佩戴者可以随时激活使用\cites{motti2020wearable}。

无人机的主要应用场景多为户外环境，用户经常需要在操作状态和非操作状态之间频繁切换，可穿戴设备的这些特性恰好符合无人机控制场景中用户的实际需求。同时，设计优秀的可穿戴设备甚至可以实现双手解放。现代无人机往往具备多功能的三维移动平台特性，降低位置控制过程中人类感官的使用负担有利于HDI应用的进一步扩展。

可穿戴设备的一个重要特点是能够作为基于视觉的手势识别技术的有效替代方案。可穿戴设备可以集成肌电传感器技术、应变传感器技术、运动传感器技术、超声波传感器技术、光电传感器技术等多种传感技术来实现手势识别。融合这些技术的可穿戴设备能够有效避免复杂背景环境的干扰，解决手势超出摄像头视野范围而无法接收指令的技术难题。例如，2025年华为技术有限公司发布的HUAWEI WATCH 5\footnote{https://consumer.huawei.com/cn/wearables/watch-5/}使用了多种传感器，融合算法来识别手势。

随着各种智能设备性能的快速提升，未来有望实现完全独立于智能手机的运行模式。因此，探索更多可穿戴设备应用场景，推进相关技术研究，将有助于显著提高人们的生活质量。

\subsection{第一人称视角无人机技术}

操作员获取视觉信息主要通过第一人称视角（First-Person View, FPV）或第三人称视角（Third-Person View, TPV）两种方式。TPV也称为外部中心视角，用户通过肉眼直接观察或通过第三方视觉传感器间接观察被控制的无人机目标，例如采用双无人机方案，通过从机摄像头观察主机的控制方式\cites{inoue2023birdviewar}。而FPV则基于被控制无人机的视觉传感器获取实时图像信息。

在现代无人机系统中，TPV条件下的人机系统中，无人机主要根据预设任务或飞行路线进行自动或半自动位置控制，人类主要扮演监督者角色。而在FPV条件下的人机系统中，无人机主要作为人类视觉感官的延伸工具，位置控制主要由人类直接执行。

这两种视角的操作方式各有优缺点，表\ref{tab:FPV And TPV}详细总结了其主要优缺点和典型适用场景。从对比分析可以看出，TPV条件下的无人机主要充当执行工具，多用于完成特定预设任务，而FPV条件下的无人机则充当操作员的代理延伸，多用于执行高难度或高风险的复杂任务。

\begin{table}[htbp]
    \centering
    % \vspace{-10pt}
    \caption{无人机FPV与TPV的比较}
    \begin{tabular}{|p{1cm}|p{3cm}|p{3cm}|p{3cm}|}
        \hline
        视角  & 优点 & 缺点 & 应用 \\ \hline
        FPV & 提供高度沉浸感和体验感，能够直接感知环境和把握空间关系。且不受人与无人机距离的限制 & 视野有限，图像质量和传输延迟会影响操作体验 & 无人机竞赛、探索与侦察、电力巡检、管道检查、沉浸式旅游和娱乐、军事侦察 \\ \hline
        TPV & 在视距内能够提高对周围信息的感知，无人机自动化后可实现人机协作操作 &  容易发生视线遮挡，视距外需要切换到其他信息源。缺乏参考物时容易误判深度信息。无人机与操作员视角坐标不一致时操作困难 & 编队表演和多无人机操作、搜救任务、农林业定期监测、物资定点投放、辅助建模 \\ \hline
    \end{tabular}
    \label{tab:FPV And TPV}
    \vspace{-10pt}
\end{table}

关于FPV无人机技术，目前最新的商业产品是DJI公司于2024年4月11日发布的Avata2无人机和Goggles 3头戴显示器。前者是专门设计的单手遥控器，后者是提供沉浸式飞行体验的头戴式显示设备（Head-Mounted Display, HMD）。

近年来，学术界也开展了一系列关于FPV条件下无人机技术的深入研究。例如，在应用领域方面，有研究探讨了FPV无人机对教育事业的积极影响\cites{sivenas2022using}以及在火灾事故应急处理中的具体应用\cites{gokul2024optimizing}。还有专门针对改善VR使用体验的研究，提出了有效减轻高动态影像引起的VR晕动症的技术方法\cites{ryu2023sickness}，以及利用身体感觉反馈构建沉浸式FPV飞行体验的创新方法\cites{cherpillod2019embodied}。此外，在控制器技术研究方面，有学者测试了FPV条件下无人机同步控制器的性能表现\cites{kim2022intuitive}。

在FPV和TPV两种不同条件下，无人机的位置控制方法存在显著差异。考虑到未来无人机技术发展更加倾向于超视距操作应用，本研究重点考虑FPV条件下的操控逻辑，设计更加自然的无人机操控模式，并通过原型设备进行实用性验证实验。

\subsection{基于深度学习的手势识别技术}
传统的机器学习模型很难从手势动作中有效提取特征信息，而深度学习模型（Deep Learning Model）的出现为这一技术难题提供了良好的解决方案。深度学习框架通常包括模型架构（Model Architecture）和学习过程（Learning Process）两个核心部分。模型架构是指模型的计算结构，即如何通过数学运算实现从输入到输出的映射；学习过程是指通过训练数据优化模型参数的方法，本质上是一个模型优化过程。模型架构包含大量可学习参数，通过学习过程进行不断优化，以寻找最优的拟合模型。

对于手势识别任务，目前比较主流的模型架构包括卷积神经网络（Convolutional Neural Networks, CNNs）和循环神经网络（Recurrent Neural Networks, RNNs）及其改进变体，如长短期记忆网络（LSTM）和门控循环单元（GRU），以及近年来兴起的Transformer模型。

卷积神经网络由一个或多个卷积层和顶层的全连接层组成，同时包括相关权重参数和池化层（Pooling Layer）。这种网络结构使得卷积神经网络能够有效利用输入数据的二维空间结构特性\cites{wiki:convolutional_neural_network}。CNNs在手势识别中具有以下重要特点\cites{wu2024gesture}：
\begin{itemize}
    \item 自动特征提取：能够自动提取边缘、纹理、形状等多层次特征信息
    \item 分层表示学习：通过多层卷积和池化操作，CNNs能够提取从低级到高级的层次化特征表示
    \item 权重共享机制：多个卷积层共享相同的权重参数集，有效减少了模型规模
    \item 平移不变性：手势在图像中的相对位置变化不会显著影响识别精度
\end{itemize}

虽然CNNs特别适合处理手势图像识别任务，但如前文所述，基于视觉传感器的手势图像识别技术受环境因素影响较大。因此，许多研究开始探索基于IMU（惯性测量单元）和CNNs的手势识别方法\cites{karnerrealtime, dahiya2024efficient,sakuma2022mlp}。与基于视觉传感器的手势图像识别类似，这类方法将多个传感器通道数据与采样时间维度构成二维输入样本，使用多个一维卷积核进行特征提取。未来的研究重点将集中于融合其他类型传感器以进一步提高识别精度\cites{dahiya2024efficient}。

LSTM和GRU都是传统RNN的重要改进模型。RNN的理论基础起源于神经科学领域，1943年McCulloch-Pitts的开创性论文首次提出了包含循环连接的神经网络模型，认为这类网络的当前活动状态可能受到过去任意时刻活动的长期影响。随后在1990年，Elman等人\cites{elman1990finding}提出了简单循环网络（Simple Recurrent Network, SRN），为现代RNN技术奠定了重要的理论基础。

传统RNN的最大技术缺陷是在处理长序列输入时容易出现梯度消失和梯度爆炸问题，因此研究者提出了LSTM网络结构\cites{hochreiter1997long}。LSTM通过引入输入门（Input Gates）、遗忘门（Forget Gates）、输出门（Output Gates）等门控机制来精确控制信息的保留、更新和丢弃过程。LSTM在手势识别中具有以下重要特点\cites{wu2024gesture}：
\begin{itemize}
    \item 时序建模能力：RNN通过循环连接将前一时刻的隐藏状态作为当前时刻的输入，因此能够有效捕获序列中的时间依赖关系和上下文信息
    \item 参数共享机制：在所有时间步中共享相同的权重参数，显著减少了模型规模
    \item 长程依赖处理：通过门控机制，长期信息能够被有效保留在记忆单元中
\end{itemize}

GRU\cites{cho2014learning}作为LSTM的简化版本，仅包含重置门（Reset Gates）和更新门（Update Gates）两个门控结构，在保持相似性能的同时显著降低了计算复杂度，使其更加适合在资源受限的移动设备上运行。

Transformer模型\cites{vaswani2017attention}最初为自然语言处理任务设计，但近年来在手势识别领域也展现出了强大的潜力。与RNN类型模型不同，Transformer完全基于自注意力机制（Self-Attention Mechanism）进行序列建模，无需循环或卷积结构。Transformer在手势识别中具有以下重要特点：
\begin{itemize}
    \item 并行计算能力：自注意力机制允许对序列中的所有位置同时进行计算，显著提升了训练效率
    \item 全局上下文建模：能够直接建模序列中任意两个位置之间的依赖关系，更好地捕获长距离依赖
    \item 位置编码机制：通过位置编码保持序列的时序信息，适合处理变长手势序列
    \item 多头注意力：通过多个注意力头从不同角度提取特征信息，增强模型的表达能力
\end{itemize}

基于CNNs、LSTM、GRU和Transformer模型，学术界已经开展了大量手势识别相关研究\cites{jiang2022multi,chen2024bilstm,chen2024ultra,li2022research,kavarthapu2017hand,valarezo2021hand,d2020transformer,wang2024continuous}

另外，从实际解决问题出发，被识别手势可以分为离散手势\cites{jiang2022multi,chen2024bilstm,chen2024ultra,li2022research,valarezo2021hand,d2020transformer,wang2024continuous}和组合序列手势\cites{kavarthapu2017hand}。

离散手势指对手势进行1对1的解释和分类，组合序列手势是指基于离散手势（如左滑、右滑、上滑、下滑、前滑、画圆等简单手势），经过排列组合得到的派生手势。与离散手势识别不同的是，组合序列手势的识别目标是，只通过部分序列长度的训练数据集的模型训练，得到变长序列的识别。比如，只在离散手势的数据集上进行训练，得到的模型可以识别如[下滑, 右滑]，[上滑, 右滑，下滑]的组合手势。

探索组合序列手势的深度学习模型可以大大减少训练数据，使得使用少量的数据就可以用于识别不同长度组合的派生手势。

组合序列手势本质上是语义编译在手势上应用，一个类似的应用就是手语识别，本研究探索其在更通用领域中的应用，比如本文描述的无人机遥控。

\subsection{研究目的和意义}

本研究致力于为HDI技术发展做出贡献。具体而言，本研究针对无人机遥控界面，提出一种适用于FPV应用场景的基于IMU传感器的可穿戴式控制设备，并基于该设备设计针对不同飞行阶段的遥控方式，通过系统性实验评估其性能和实用性。

本研究的具体内容包括以下几个方面：

\begin{itemize}
    \item 新型可穿戴设备系统设计：基于ESP32微控制器和多传感器单元构建多交互模式的无人机遥控系统
    \item 飞行状态手势映射方案设计：基于所设计的系统，针对飞行状态下的无人机控制需求，通过连续手势动作实现对无人机空间位置的精确操控
    \item 多方案对比实验研究：基于前述系统，在虚拟环境下针对飞行状态下的无人机控制，通过两次用户实验与现有控制方案进行对比分析，验证所提方案的技术可行性
    \item 基于深度学习的序列手势识别性能分析：为弥补前述手势映射方案在输入维度方面的局限性，深入分析基于深度学习模型的序列手势识别性能和实际应用可行性
\end{itemize}

目前，FPV无人机市场正在经历快速增长，探索相关的自然交互技术具有重要的实际应用意义。在娱乐和日常生活应用方面，随着头戴式显示器技术与无人机技术的深度融合与技术成熟，具有高度沉浸感的FPV无人机正在向普通消费者群体普及，本研究成果有望为相关产品的技术开发和产业化推广提供重要支撑。

\subsection{论文结构}

本研究其余部分的构成如下：

第2章深入调研和分析与手势识别和无人机控制相关的国内外研究现状，重点梳理基于IMU传感器的手势识别技术、深度学习在手势识别中的应用、可穿戴设备在无人机控制中的研究进展等核心技术领域的发展脉络和最新成果。

第3章详细介绍用于验证所提方案的硬件设备原型和软件模拟器系统的设计与实现过程，包括硬件架构设计、传感器选型与集成、软件算法实现、通信协议设计等关键技术环节。

第4章展示初版控制方案的设计思路，设计并实施与传统GamePad控制器的对比实验，通过定量和定性分析方法对实验结果进行深入讨论，验证所提方案的基本可行性。

第5章设计并实施第二次系统性实验，将所提方案与多种现有控制方式进行全面比较，采用多维度评估指标对实验结果进行深入分析，全面验证方案的优势和局限性。

第6章作为遥控系统功能的重要补充，深入分析基于深度学习模型的序列手势识别性能，探索在实际系统中部署深度学习模型的技术可行性和实现路径。

第7章全面总结本研究的主要结论和创新贡献，客观分析研究工作的局限性，并对未来相关技术的发展方向和研究课题进行展望。


%% ---DO NOT MODIFY BEGIN---
\ifx\allfiles\undefined
\end{document}
\fi
%% ---DO NOT MODIFY END---